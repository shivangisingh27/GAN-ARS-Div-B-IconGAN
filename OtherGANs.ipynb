{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-01T04:19:48.055693Z",
     "start_time": "2024-05-01T04:19:47.388349Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('train-00000-of-00001-b64601da56687a05.parquet')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T04:20:25.748607Z",
     "start_time": "2024-05-01T04:20:25.733330Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.head())",
   "id": "5bf7c563e5b28301",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image  \\\n",
      "0  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
      "1  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
      "2  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
      "3  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
      "4  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...   \n",
      "\n",
      "                                                text  \n",
      "0  \"a logo of coffee shop, take-away coffee cardb...  \n",
      "1  \"a logo of coffee shop, White round background...  \n",
      "2  \"a logo of coffee shop, image of a filled cup ...  \n",
      "3  \"a logo of cafe restaurant bar pizzeria with a...  \n",
      "4  \"a logo of cafe restaurant bar with a circle w...  \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T04:26:52.683005Z",
     "start_time": "2024-05-01T04:26:50.910590Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install data model utils",
   "id": "1ee6c82d4c027937",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data\r\n",
      "  Downloading data-0.4.tar.gz (7.0 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[31mERROR: Could not find a version that satisfies the requirement model (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for model\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[?25h"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T04:26:21.613135Z",
     "start_time": "2024-05-01T04:26:20.968154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from data import AttnDataset, resize_img\n",
    "from model import RNN_ENCODER, G_NET\n",
    "from utils import build_models, build_transform, gen_example\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_parquet('your_dataset.parquet')\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained models\n",
    "text_encoder, netG = build_models()\n",
    "\n",
    "# Define image transformation\n",
    "transform = build_transform()\n",
    "\n",
    "# Define data loader\n",
    "dataset = AttnDataset(df, transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "# Generate images\n",
    "for idx, (text, img_bytes) in enumerate(dataloader):\n",
    "    # Preprocess text\n",
    "    text = text[0]  # Extract text from batch\n",
    "    text = text.lower()  # Convert text to lowercase (if necessary)\n",
    "    \n",
    "    # Preprocess image\n",
    "    img_bytes = img_bytes[0]  # Extract image bytes from batch\n",
    "    img = Image.open(io.BytesIO(img_bytes))\n",
    "    img = resize_img(img, 64)  # Resize image to desired size (assuming 64x64)\n",
    "\n",
    "    # Convert image to tensor and move to device\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Tokenize text\n",
    "    captions = [text.split()]\n",
    "    cap_lens = [len(captions[0])]\n",
    "    captions = torch.tensor(captions).to(device)\n",
    "    cap_lens = torch.tensor(cap_lens).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, _, _, _, fake_imgs, _, _ = gen_example(text_encoder, netG, captions, cap_lens)\n",
    "    \n",
    "    # Convert generated images from tensors to PIL images\n",
    "    fake_imgs = fake_imgs[-1].cpu()\n",
    "    fake_imgs = fake_imgs.view(-1, 3, 64, 64)  # Assuming image size is 64x64\n",
    "    fake_imgs = fake_imgs.mul(0.5).add(0.5)\n",
    "    fake_imgs = fake_imgs.mul(255).byte()\n",
    "    \n",
    "    # Save or display generated images\n",
    "    for i in range(fake_imgs.size(0)):\n",
    "        img = fake_imgs[i].permute(1, 2, 0)\n",
    "        img = Image.fromarray(img.numpy())\n",
    "        img.save(f\"generated_image_{idx}_{i}.png\")\n"
   ],
   "id": "20d906358451bf81",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AttnDataset, resize_img\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RNN_ENCODER, G_NET\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m build_models, build_transform, gen_example\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'data'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6430ddd0ec0b1b21"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
